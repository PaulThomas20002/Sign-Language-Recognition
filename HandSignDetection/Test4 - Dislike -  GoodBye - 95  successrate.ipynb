{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd0f9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "\n",
    "def is_like_gesture(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    thumb_ip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]\n",
    "    thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP]\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    index_pip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP]\n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    middle_pip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "    ring_pip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_PIP]\n",
    "    ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "    pinky_pip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_PIP]\n",
    "    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]\n",
    "\n",
    "    # Check thumb and other finger positions\n",
    "    thumb_folded = thumb_tip.y > thumb_ip.y > thumb_mcp.y\n",
    "    index_folded = index_tip.y > index_pip.y > index_mcp.y\n",
    "    middle_folded = middle_tip.y > middle_pip.y > middle_mcp.y\n",
    "    ring_folded = ring_tip.y > ring_pip.y > ring_mcp.y\n",
    "    pinky_folded = pinky_tip.y > pinky_pip.y > pinky_mcp.y\n",
    "\n",
    "    # Check thumb and other finger distances\n",
    "    thumb_pinky_dist = math.sqrt((thumb_tip.x - pinky_tip.x) ** 2 + (thumb_tip.y - pinky_tip.y) ** 2)\n",
    "    fingers_dist = math.sqrt((index_tip.x - pinky_tip.x) ** 2 + (index_tip.y - pinky_tip.y) ** 2)\n",
    "\n",
    "    # Check if all conditions for dislike gesture are satisfied\n",
    "    if thumb_folded and index_folded and middle_folded and ring_folded and pinky_folded and thumb_pinky_dist > fingers_dist:\n",
    "        return \"Dislike\"\n",
    "    \n",
    "    # Check if all conditions for like gesture are satisfied\n",
    "    if thumb_folded and index_folded and middle_folded and ring_folded and pinky_folded and thumb_tip.y < index_tip.y:\n",
    "        return \"Like\"\n",
    "    \n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        # Flip the image horizontally for a mirrored display\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Convert the image color space from BGR to RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the image and detect hands\n",
    "        results = hands.process(image_rgb)\n",
    "        \n",
    "        # Check if hands are detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw hand landmarks on the image\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                # Check if the gesture is a like or dislike gesture\n",
    "                gesture = is_like_gesture(hand_landmarks)\n",
    "                if gesture == \"Dislike\":\n",
    "                    cv2.putText(image, \"Dislike\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                elif gesture == \"Like\":\n",
    "                    cv2.putText(image, \"Like\", (250, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 200, 255), 2)\n",
    "                else:\n",
    "                    cv2.putText(image, \"unknown\", (300, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (50, 200, 255), 2)\n",
    "        \n",
    "        # Display the image with annotated hand landmarks\n",
    "        cv2.imshow('Sign Language Detection', image)\n",
    "        \n",
    "        # Exit loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b466b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
